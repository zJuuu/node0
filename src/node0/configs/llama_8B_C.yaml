model_config:
  class_name: node0.models.llama.arguments.LlamaArguments
  init_args:
    hidden_dim: 4096
    n_heads: 32
    n_kv_heads: 8
    ffn_dim_multiplier: 1.3
    multiple_of: 1024
    rope_theta: 500000
    num_hidden_layers: 1
    qk_norm: True
    norm_reorder: True
    trainable_rmsnorm: False
    compression_rate: 100
    use_compression: True
    max_seq_len: 4096
    ss_component: 'https://d2exiwjpgw0bxb.cloudfront.net/subspace_compression/8B_C/subspace_comp.pt'
 
optim_config:
  class_name: torch.optim.AdamW
  init_args:
    lr: 0.0003
    weight_decay: 0.1

grad_avg_config:
  class_name: node0.server.power_sgd_averager.PowerSGDGradientAverager
  init_args:
    averager_rank: 64

# Scheduler
scheduler: linear
num_warmup_steps: 4000
num_training_steps: 100000

# Training
num_stages: 32
clip_grad_norm: 1.0
weight_decay: 0.0
compression: NONE
min_batch_size: 1
max_batch_size: 1
averaging_target_batch_size: 1024
matchmaking_time: 45
averaging_timeout: 120
request_timeout: 3
sparse_avg: 0.05
average_state_every: 5
load_state_timeout: 150
max_allowed_stale: 5
num_dht: 5